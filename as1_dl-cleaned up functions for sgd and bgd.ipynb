{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e3c94098",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.datasets import fashion_mnist\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "44b9c00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cab584d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc=OneHotEncoder(sparse=False)\n",
    "y_train_new = np.array(y_train.reshape(len(y_train), 1))\n",
    "yy = enc.fit_transform(y_train_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "32163ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_split(bs,X_train,Y_train,X_test,Y_test):\n",
    "    x_train, y_train_cat = shuffle(X_train,Y_train)\n",
    "    x_test,y_test=shuffle(X_test,Y_test)\n",
    "    x_train = x_train.reshape(x_train.shape[0],784)\n",
    "    x_test = x_test.reshape(x_test.shape[0],784)\n",
    "    x_train=x_train/np.max(x_train)\n",
    "    x_test=x_test/np.max(x_test)\n",
    "    enc=OneHotEncoder(sparse=False)\n",
    "    y_train = enc.fit_transform(np.array(y_train_cat.reshape(len(y_train_cat), 1)))\n",
    "    y_train_bs=[]\n",
    "    x_train_bs=[]\n",
    "    if x_train.shape[0]%bs==0:\n",
    "        x_train_bs=np.vsplit(x_train,int(x_train.shape[0]/bs))\n",
    "        y_train_bs=np.vsplit(y_train,int(x_train.shape[0]/bs))\n",
    "    else:\n",
    "        x_train_bs=np.vsplit(x_train[0:x_train.shape[0]-x_train.shape[0]%bs],math.floor(x_train[0:x_train.shape[0]-x_train.shape[0]%bs].shape[0]/bs))\n",
    "        x_train_bs.append(x_train[x_train.shape[0]-x_train.shape[0]%bs:x_train.shape[0]])\n",
    "        y_train_bs=np.vsplit(y_train[0:x_train.shape[0]-x_train.shape[0]%bs],math.floor(x_train[0:x_train.shape[0]-x_train.shape[0]%bs].shape[0]/bs))\n",
    "        y_train_bs.append(y_train[x_train.shape[0]-x_train.shape[0]%bs:x_train.shape[0]])\n",
    "    return x_train_bs,y_train_bs,x_test,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1b627626",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_func(x):\n",
    "    log_func =1 / (1 + np.exp(-x))\n",
    "    return log_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "81115da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_softmax(x):\n",
    "    sf=[]\n",
    "    e_x = np.exp(x)\n",
    "    for i in range(x.shape[1]):\n",
    "        sf.append(e_x[:,i]/np.sum(e_x[:,i]))\n",
    "    return sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a5839732",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(y_pred,y):\n",
    "    samp=y.shape[0]\n",
    "    loss=np.empty(samp)\n",
    "    for i in range(samp):\n",
    "        loss[i]=-np.dot(y_pred[i],np.transpose(y[i]))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6cbf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size=784\n",
    "no_hidden =3\n",
    "size_hidden=[200,100,50]\n",
    "no_output=10\n",
    "learning_rate=0.15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d78f5a",
   "metadata": {},
   "source": [
    "## Tryout after debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "61c870a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_params(input_size,no_hidden,size_hidden,no_output):\n",
    "    std=1e-2\n",
    "    w=[]\n",
    "    w.append(std*np.sqrt(1./size_hidden[0])*np.random.rand(size_hidden[0],input_size))\n",
    "    b=[]\n",
    "    b.append(std*np.random.rand(size_hidden[0],1))\n",
    "    for i in range(no_hidden-1):\n",
    "        w.append(std*np.sqrt(1./size_hidden[i+1])*np.random.rand(size_hidden[i+1],size_hidden[i]))\n",
    "        b.append(std*np.random.rand(size_hidden[i+1],1)) \n",
    "    w.append(std*np.sqrt(1./no_output)*np.random.rand(no_output,size_hidden[-1]))\n",
    "    b.append(std*np.random.rand(no_output,1))\n",
    "    return w,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "900a9c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_prop(eg,x_train,w,b):\n",
    "    a=[]\n",
    "    h=[]\n",
    "    h.append(x_train[eg].T)\n",
    "    for i in range(no_hidden):\n",
    "        a.append(np.dot(w[i],h[i])+b[i])\n",
    "        h.append(logistic_func(a[i]))\n",
    "    a_f=np.dot(w[no_hidden],h[no_hidden])+b[no_hidden]\n",
    "    y_pred= func_softmax(a_f)\n",
    "    return a,h,a_f,y_pred\n",
    "\n",
    "def backward_prop(eg,y_train,y_pred,w,b,h,a,a_f,no_hidden):\n",
    "    grad_a=[None]*(no_hidden+1)#initialise a list to add the gradients corresponding to each layer C\n",
    "    grad_w=[None]*(no_hidden+1)#\n",
    "    grad_b=[None]*(no_hidden+1)#\n",
    "    grad_h=[None]*(no_hidden)#\n",
    "    grad_a[no_hidden]=-(y_train[eg]-y_pred)\n",
    "    for k in range(no_hidden,-1,-1):\n",
    "        grad_w[k]=np.dot(h[k],grad_a[k])\n",
    "        grad_b[k]= np.sum(grad_a[k], axis=0, keepdims=True)\n",
    "        if k >= 1:\n",
    "            grad_h[k-1]=np.dot(grad_a[k],w[k])\n",
    "            grad_a[k-1]=grad_h[k-1]*(logistic_func(a[k-1].T)*(1-logistic_func(a[k-1].T)))\n",
    "    return grad_b,grad_w \n",
    "\n",
    "def param_update(w,b,grad_w,grad_b,learning_rate):\n",
    "    for i in range(no_hidden+1):\n",
    "        w[i]=w[i]-(learning_rate*grad_w[i].T)\n",
    "        b[i]=b[i]-(learning_rate*grad_b[i].T)\n",
    "    return w,b\n",
    "\n",
    "def test_model(w,b,x_test,y_test): \n",
    "    an=[]\n",
    "    hn=[]\n",
    "    hn.append(x_test.T)\n",
    "    for i in range(no_hidden):\n",
    "        an.append(np.dot(w[i],hn[i])+b[i])\n",
    "        hn.append(logistic_func(an[i]))\n",
    "    a_fn=np.dot(w[no_hidden],hn[no_hidden])+b[no_hidden]\n",
    "    y_pred1= func_softmax(a_fn)\n",
    "    y_final=np.empty(10000)\n",
    "    for i in range(10000):\n",
    "        y_final[i]=y_pred1[i].argmax()\n",
    "    return accuracy_score(y_test, y_final)\n",
    "\n",
    "def train_model(input_size,no_hidden,size_hidden,no_output,bs,x_train,y_train,x_test,y_test,max_iterations,learning_rate):\n",
    "    ct=1;\n",
    "    x_train,y_train,x_test,y_test=batch_split(batch_size,x_train,y_train,x_test,y_test)\n",
    "    no_batch=len(x_train)\n",
    "    w,b=initialize_params(input_size,no_hidden,size_hidden,no_output)\n",
    "    while ct<=max_iterations:\n",
    "        for eg in range(no_batch):\n",
    "            a,h,a_f,y_pred=forward_prop(eg,x_train,w,b)\n",
    "            grad_b,grad_w=backward_prop(eg,y_train,y_pred,w,b,h,a,a_f,no_hidden)\n",
    "            w,b=param_update(w,b,grad_w,grad_b,learning_rate)\n",
    "        acc=test_model(w,b,x_test,y_test)\n",
    "        print('Epoch',ct,'Accuracy',acc)\n",
    "        ct+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "3842e12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size=784\n",
    "no_hidden =3\n",
    "size_hidden=[200,100,50]\n",
    "no_output=10\n",
    "learning_rate=0.15\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "max_iterations=10\n",
    "batch_size=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "5547a621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Accuracy 0.754\n",
      "Epoch 2 Accuracy 0.8168\n",
      "Epoch 3 Accuracy 0.8265\n",
      "Epoch 4 Accuracy 0.831\n",
      "Epoch 5 Accuracy 0.8374\n",
      "Epoch 6 Accuracy 0.83\n",
      "Epoch 7 Accuracy 0.8337\n",
      "Epoch 8 Accuracy 0.8254\n",
      "Epoch 9 Accuracy 0.8347\n",
      "Epoch 10 Accuracy 0.8219\n"
     ]
    }
   ],
   "source": [
    "train_model(input_size,no_hidden,size_hidden,no_output,bs,x_train,y_train,x_test,y_test,max_iterations,learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "21431c78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32226270",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
